{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smaugcow/test_test/blob/main/examples/notebooks/pytorch/byol.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "This example requires the following dependencies to be installed:\n",
        "pip install lightly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка необходимых библиотек\n",
        "!pip install lightly\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nF_zmeTVZnAO",
        "outputId": "519c95c0-2232-4c22-dca4-653ac40802c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nF_zmeTVZnAO",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightly in /usr/local/lib/python3.11/dist-packages (1.5.19)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from lightly) (2025.1.31)\n",
            "Requirement already satisfied: hydra-core>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from lightly) (1.3.2)\n",
            "Requirement already satisfied: lightly_utils~=0.0.0 in /usr/local/lib/python3.11/dist-packages (from lightly) (0.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.0.2)\n",
            "Requirement already satisfied: python_dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.32.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from lightly) (1.17.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.11/dist-packages (from lightly) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from lightly) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from lightly) (0.21.0+cu124)\n",
            "Requirement already satisfied: pydantic>=1.10.5 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.11.1)\n",
            "Requirement already satisfied: pytorch_lightning>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.5.1)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.3.0)\n",
            "Requirement already satisfied: aenum>=3.1.11 in /usr/local/lib/python3.11/dist-packages (from lightly) (3.1.15)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly) (24.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from lightly_utils~=0.0.0->lightly) (11.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (2.33.0)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (4.13.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (0.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning>=1.0.4->lightly) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2025.3.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning>=1.0.4->lightly) (1.7.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning>=1.0.4->lightly) (0.14.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lightly) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lightly) (3.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->lightly) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning>=1.0.4->lightly) (75.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->lightly) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт необходимых библиотек\n",
        "import copy\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from lightly.loss import NegativeCosineSimilarity\n",
        "from lightly.models.modules import BYOLPredictionHead, BYOLProjectionHead\n",
        "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
        "from lightly.transforms.byol_transform import (\n",
        "    BYOLTransform,\n",
        "    BYOLView1Transform,\n",
        "    BYOLView2Transform,\n",
        ")\n",
        "from lightly.utils.scheduler import cosine_schedule\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "y5nvenaeZoR7",
        "outputId": "88a34470-a8cb-43f0-8e07-f1587e327f45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "y5nvenaeZoR7",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определяем класс BYOL (Bootstrap Your Own Latent)\n",
        "# Это self-supervised learning архитектура, не требующая аннотированных меток для обучения\n",
        "class BYOL(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "        # Определяем базовый свёрточный слой (backbone), используем ResNet-18 с обрезанной головой\n",
        "        self.backbone = backbone\n",
        "        # Создаем проекционный и предсказательный головы, обе используют линейные слои с активацией ReLU\n",
        "        self.projection_head = BYOLProjectionHead(512, 1024, 256)\n",
        "        self.prediction_head = BYOLPredictionHead(256, 1024, 256)\n",
        "\n",
        "        # Моментум версии backbone и проекционной головы, которые обучаются медленнее\n",
        "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
        "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
        "\n",
        "        # Деактивируем вычисление градиентов для моментум структур\n",
        "        deactivate_requires_grad(self.backbone_momentum)\n",
        "        deactivate_requires_grad(self.projection_head_momentum)\n",
        "\n",
        "    # Метод forward для основной модели\n",
        "    def forward(self, x):\n",
        "        # Получаем представления данных от backbone\n",
        "        y = self.backbone(x).flatten(start_dim=1)\n",
        "        # Пропускаем через проекционную голову\n",
        "        z = self.projection_head(y)\n",
        "        # Пропускаем через предсказательную голову\n",
        "        p = self.prediction_head(z)\n",
        "        return p\n",
        "\n",
        "    # Метод forward для моментум версии модели\n",
        "    def forward_momentum(self, x):\n",
        "        y = self.backbone_momentum(x).flatten(start_dim=1)\n",
        "        z = self.projection_head_momentum(y)\n",
        "        z = z.detach()  # Отключаем градиенты для этого выхода, чтобы не обновлять эту часть сети\n",
        "        return z\n",
        "\n",
        "# Инициализация модели с использованием ResNet-18 в качестве backbone\n",
        "resnet = torchvision.models.resnet18(pretrained=False)\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])  # Убираем последний полносвязный слой\n",
        "model = BYOL(backbone)\n",
        "\n",
        "# Использование GPU, если доступен\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qqaXR5A_ZpfO",
        "outputId": "26c0a5cd-1178-4175-cc55-fe89405696ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qqaXR5A_ZpfO",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BYOL(\n",
              "  (backbone): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (projection_head): BYOLProjectionHead(\n",
              "    (layers): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (prediction_head): BYOLPredictionHead(\n",
              "    (layers): Sequential(\n",
              "      (0): Linear(in_features=256, out_features=1024, bias=False)\n",
              "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (backbone_momentum): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (projection_head_momentum): BYOLProjectionHead(\n",
              "    (layers): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=1024, bias=False)\n",
              "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовка данных CIFAR10 для обучения\n",
        "# Используем трансформации для создания двух различных представлений одного и того же изображения\n",
        "transform = BYOLTransform(\n",
        "    view_1_transform=BYOLView1Transform(input_size=32, gaussian_blur=0.0),\n",
        "    view_2_transform=BYOLView2Transform(input_size=32, gaussian_blur=0.0),\n",
        ")\n",
        "\n",
        "# Загрузка датасета CIFAR10 с применением BYOL трансформаций\n",
        "dataset = torchvision.datasets.CIFAR10(\n",
        "    \"datasets/cifar10\", download=True, transform=transform\n",
        ")\n",
        "\n",
        "# Создание DataLoader для эффективной загрузки данных во время обучения\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=256,  # Использование достаточно большого размера для улучшения стабилизации градиентов\n",
        "    shuffle=True,  # Перемешивание данных для каждой эпохи для улучшения качества обучения\n",
        "    drop_last=True,  # Отбрасываем последний батч, если он меньше заявленного размера\n",
        "    num_workers=8,  # Используем несколько потоков для ускорения загрузки данных\n",
        ")\n",
        "\n",
        "# Определение функции потерь: NegativeCosineSimilarity используется для минимизации угловой дистанции\n",
        "criterion = NegativeCosineSimilarity()\n",
        "\n",
        "# Использование стохастического градиентного спуска для обновления весов сети\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.06)"
      ],
      "metadata": {
        "id": "YxevcWx2ZraE",
        "outputId": "6f21f139-f30e-47b9-c895-5e5b290cccab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YxevcWx2ZraE",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n",
            "100%|██████████| 170M/170M [00:02<00:00, 66.7MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Начало обучения модели\n",
        "epochs = 10  # Количество эпох, на протяжении которых будет проходить обучение\n",
        "all_avg_losses = []\n",
        "\n",
        "print(\"Starting Training\")\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0  # Инициализируем переменную для накопления потерь\n",
        "\n",
        "    # Косинусное расписание изменения моментума для более плавного обучения\n",
        "    momentum_val = cosine_schedule(epoch, epochs, 0.996, 1)\n",
        "\n",
        "    for batch in dataloader:\n",
        "        x0, x1 = batch[0]  # Получаем два различных представления одного батча изображений\n",
        "\n",
        "        # Обновляем моментум весов для backbone и проекционной головы\n",
        "        update_momentum(model.backbone, model.backbone_momentum, m=momentum_val)\n",
        "        update_momentum(model.projection_head, model.projection_head_momentum, m=momentum_val)\n",
        "\n",
        "        # Перемещаем данные на устройство (GPU или CPU)\n",
        "        x0, x1 = x0.to(device), x1.to(device)\n",
        "\n",
        "        # Прямое распространение для двух представлений\n",
        "        p0, p1 = model(x0), model(x1)\n",
        "        # Прямое распространение для моментум версии модели\n",
        "        z0, z1 = model.forward_momentum(x0), model.forward_momentum(x1)\n",
        "\n",
        "        # Вычисляем loss как среднее между двумя противоположными парами представлений\n",
        "        loss = 0.5 * (criterion(p0, z1) + criterion(p1, z0))\n",
        "        total_loss += loss.item()  # Накопление потерь в целях логирования\n",
        "\n",
        "        # Шаги обратного распространения и оптимизации\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    # Вычисляем среднюю потерю за одну эпоху и добавляем её для логирования\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    all_avg_losses.append(avg_loss)\n",
        "    print(f\"Epoch: {epoch+1}/{epochs}, Avg Loss: {avg_loss:.5f}\")"
      ],
      "metadata": {
        "id": "dNdllFGCZtFO",
        "outputId": "7730ff63-e229-4751-974b-79d9d79badfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dNdllFGCZtFO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Построение графика потерь для визуализации обучения\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, epochs + 1), all_avg_losses, marker='o', color='b', label='Train Loss')\n",
        "plt.title('Average Loss over Epochs for BYOL Training')\n",
        "plt.xlabel('Epochs')  # Метка оси x\n",
        "plt.ylabel('Average Loss')  # Метка оси y\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IE3ni5LlZvH0"
      },
      "id": "IE3ni5LlZvH0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для извлечения признаков из данных\n",
        "def extract_features(dataloader, model):\n",
        "    model.eval()  # Перевод модели в режим оценки (выключает dropout, batch norm и др.)\n",
        "    features, labels = [], []\n",
        "    with torch.no_grad():  # Отключаем градиенты для ускорения и снижения потребления памяти\n",
        "        for (x, y) in dataloader:\n",
        "            x = x.to(device)\n",
        "            feats = model.backbone(x).flatten(start_dim=1)  # Извлекаем признаки и преобразуем их в плоский вектор\n",
        "            features.append(feats.cpu().numpy())\n",
        "            labels.extend(y.numpy())\n",
        "    return np.concatenate(features), np.array(labels)"
      ],
      "metadata": {
        "id": "oCaL82fGZwxV"
      },
      "id": "oCaL82fGZwxV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание данных для KNN классификатора\n",
        "transform_test = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),  # Конвертация изображений в тензоры\n",
        "    torchvision.transforms.Normalize((0.5,), (0.5,)),  # Нормализация данных для глубоких моделей\n",
        "])\n",
        "\n",
        "# Загрузка тренировочного и тестового набора данных с новыми трансформациями\n",
        "train_dataset_knn = torchvision.datasets.CIFAR10(\n",
        "    \"datasets/cifar10\", train=True, transform=transform_test, download=True\n",
        ")\n",
        "test_dataset_knn = torchvision.datasets.CIFAR10(\n",
        "    \"datasets/cifar10\", train=False, transform=transform_test, download=True\n",
        ")\n",
        "\n",
        "# Создание DataLoader для загрузки данных в KNN\n",
        "dataloader_train_knn = torch.utils.data.DataLoader(\n",
        "    train_dataset_knn, batch_size=256, shuffle=False, num_workers=8)\n",
        "dataloader_test_knn = torch.utils.data.DataLoader(\n",
        "    test_dataset_knn, batch_size=256, shuffle=False, num_workers=8)"
      ],
      "metadata": {
        "id": "QG2NX3QJZxPX"
      },
      "id": "QG2NX3QJZxPX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Извлечение признаков и обучение KNN классификатора\n",
        "features_train, labels_train = extract_features(dataloader_train_knn, model)\n",
        "features_test, labels_test = extract_features(dataloader_test_knn, model)\n",
        "\n",
        "# Инициализация и обучение KNN классификатора на признаках, извлеченных из SSL модели\n",
        "knn_ssl = KNeighborsClassifier(n_neighbors=5)  # Используем 5 ближайших соседей\n",
        "knn_ssl.fit(features_train, labels_train)  # Обучение модели KNN\n",
        "predictions_ssl = knn_ssl.predict(features_test)  # Предсказания на тестовом наборе данных\n",
        "accuracy_ssl = accuracy_score(labels_test, predictions_ssl)  # Вычисление точности модели\n",
        "\n",
        "print(f\"Accuracy using SSL features: {accuracy_ssl:.2f}\")\n",
        "\n",
        "# Реализация KNN на сырых данных (без извлеченных признаков)\n",
        "def flatten_images(dataloader):\n",
        "    images, labels = [], []\n",
        "    for x, y in dataloader:\n",
        "        images.append(x.view(x.size(0), -1).numpy())  # Преобразование изображений в вектор\n",
        "        labels.extend(y.numpy())\n",
        "    return np.concatenate(images), np.array(labels)\n",
        "\n",
        "# Извлечение признаков с сырых изображений\n",
        "raw_train, raw_train_labels = flatten_images(dataloader_train_knn)\n",
        "raw_test, raw_test_labels = flatten_images(dataloader_test_knn)\n",
        "\n",
        "# Инициализация и обучение KNN классификатора на сырых изображениях\n",
        "knn_raw = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_raw.fit(raw_train, raw_train_labels)\n",
        "predictions_raw = knn_raw.predict(raw_test)\n",
        "accuracy_raw = accuracy_score(raw_test_labels, predictions_raw)  # Вычисление точности для сырых данных\n",
        "\n",
        "print(f\"Accuracy using raw images: {accuracy_raw:.2f}\")"
      ],
      "metadata": {
        "id": "-cohejj9ZyZy"
      },
      "id": "-cohejj9ZyZy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сравнение и визуализация точности KNN классификаторов\n",
        "accuracies = [accuracy_ssl, accuracy_raw]\n",
        "labels = ['SSL Features', 'Raw Images']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(labels, accuracies, color=['navy', 'gray'])\n",
        "plt.title('Comparison of KNN Classifier Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n",
        "\n",
        "# Вывод итоговых результатов и сравнение\n",
        "print(\"\\nComparison of KNN Classifier Performance:\")\n",
        "print(f\"Accuracy with SSL features: {accuracy_ssl:.2f}\")\n",
        "print(f\"Accuracy with raw pixels: {accuracy_raw:.2f}\")\n",
        "\n",
        "# Вывод о том, какая из моделей показала лучшую точность\n",
        "if accuracy_ssl > accuracy_raw:\n",
        "    print(\"\\nSSL features improved the classification accuracy.\")\n",
        "else:\n",
        "    print(\"\\nRaw pixels provided better classification results.\")"
      ],
      "metadata": {
        "id": "gDVx2raqZDWr"
      },
      "id": "gDVx2raqZDWr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}